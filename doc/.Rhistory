packages.used <- c("ggplot2", "dplyr", "tidytext", "wordcloud", "stringr", "ggridges")
# check packages that need to be installed.
packages.needed <- setdiff(packages.used, intersect(installed.packages()[,1], packages.used))
# install additional packages
if(length(packages.needed) > 0) {
install.packages(packages.needed, dependencies = TRUE, repos = 'http://cran.us.r-project.org')
}
library(ggplot2)
library(dplyr)
library(tidytext)
library(wordcloud)
library(stringr)
library(ggridges)
source("../libs/multiplot.R")
packages.used <- c("ggplot2", "dplyr", "tidytext", "wordcloud", "stringr", "ggridges")
# check packages that need to be installed.
packages.needed <- setdiff(packages.used, intersect(installed.packages()[,1], packages.used))
# install additional packages
if(length(packages.needed) > 0) {
install.packages(packages.needed, dependencies = TRUE, repos = 'http://cran.us.r-project.org')
}
library(ggplot2)
library(dplyr)
library(tidytext)
library(wordcloud)
library(stringr)
library(ggridges)
source("../libs/multiplot.R")
packages.used <- c("ggplot2", "dplyr", "tidytext", "wordcloud", "stringr", "ggridges")
# check packages that need to be installed.
packages.needed <- setdiff(packages.used, intersect(installed.packages()[,1], packages.used))
# install additional packages
if(length(packages.needed) > 0) {
install.packages(packages.needed, dependencies = TRUE, repos = 'http://cran.us.r-project.org')
}
library(ggplot2)
library(dplyr)
library(tidytext)
library(wordcloud)
library(stringr)
library(ggridges)
source("../libs/multiplot.R")
packages.used <- c("ggplot2", "dplyr", "tidytext", "wordcloud", "stringr", "ggridges")
# check packages that need to be installed.
packages.needed <- setdiff(packages.used, intersect(installed.packages()[,1], packages.used))
# install additional packages
if(length(packages.needed) > 0) {
install.packages(packages.needed, dependencies = TRUE, repos = 'http://cran.us.r-project.org')
}
library(ggplot2)
library(dplyr)
library(tidytext)
library(wordcloud)
library(stringr)
library(ggridges)
source("../lib/multiplot.R")
spooky <- read.csv('../data/spooky.csv', as.is = TRUE)
head(spooky)
summary(spooky)
spooky$text[1]
spooky$text[13494]
spooky$text[666]
sum(is.na(spooky))
spooky$author <- as.factor(spooky$author)
spooky_wrd <- unnest_tokens(spooky, word, text)
head(spooky_wrd)
head(stop_words)
tail(stop_words)
spooky_wrd <- anti_join(spooky_wrd, stop_words, by = "word")
head(spooky_wrd)
p1 <- ggplot(spooky) +
geom_bar(aes(author, fill = author)) +
theme(legend.position = "none")
spooky$sen_length <- str_length(spooky$text)
head(spooky$sen_length)
p2 <- ggplot(spooky) +
geom_density_ridges(aes(sen_length, author, fill = author)) +
scale_x_log10() +
theme(legend.position = "none") +
labs(x = "Sentence length [# characters]")
spooky_wrd$word_length <- str_length(spooky_wrd$word)
head(spooky_wrd$word_length)
p3 <- ggplot(spooky_wrd) +
geom_density(aes(word_length, fill = author), bw = 0.05, alpha = 0.3) +
scale_x_log10() +
theme(legend.position = "none") +
labs(x = "Word length [# characters]")
layout <- matrix(c(1, 2, 1, 3), 2, 2, byrow = TRUE)
multiplot(p1, p2, p3, layout = layout)
words <- names(table(spooky_wrd$word))
freqs <- table(spooky_wrd$word)
head(sort(freqs, decreasing = TRUE))
wordcloud(words, freqs, max.words = 50, color = c("purple4", "red4", "black"))
knitr::opts_chunk$set(echo = TRUE)
packages.used <- c("ggplot2", "dplyr", "tidytext", "wordcloud", "stringr", "ggridges")
knitr::opts_chunk$set(echo = TRUE)
# What format are the data in?
class(spooky)
# What are the dimensions of the data?
# As we can see, the Spooky Dataset contains 19,579 sentences.
dim(spooky)
# How are the data labeled, and what types are they?
# As we can see, each row has a unique sentence ID, the text of the single sentence
# that corresponds, and the initials of the author: {"EAP", "MWS", "HPL"}.
summary(spooky)
# Let's look at a couple entries.
head(spooky)
# Are there any missing entries? As discussed in class, no!
sum(is.na(spooky))
EAP <- arrange(EAP, desc(charLength))
# First, we check if dplyr is installed, and install it if necessary, so that
# its convenient pipeline notation is immediately available. Then we load dplyr.
if (!("dplyr" %in% installed.packages())){
install.packages("dplyr")
}
library(dplyr)
# Now, we rewrite code equivalent to that provided in the in-class tutorial,
# using the pipeline operator instead for more intuitive presentation.
# Alphabetic list of all packages used in this analysis.
packages.used <- c("ggplot2",
"graphics",
"ngram",
"NLP",
"openNLP",
"qdap",
"quanteda",
"RColorBrewer",
"rJava", # Needed for openNLP
"rmarkdown", # Needed for pretty floating table of contents
"sentimentr",
"stringr",
"tibble",
"tidyr",
"tidytext",
"tm",
"topicmodels",
"wordcloud")
# Determine what packages are not yet installed, and install them.
packages.needed <-
# What packages does this project use?
packages.used %>%
# What packages are *both* being used *and* already installed?
intersect(installed.packages()[,1]) %>%
# What packages are used, but *not* installed?
setdiff(packages.used, .)
if(length(packages.needed) > 0) {
install.packages(packages.needed,
dependencies = TRUE,
repos = 'http://cran.us.r-project.org',
quiet = TRUE)}
# The openNLPmodels.en package is not available from the CRAN repository.
# So we'll include a separate condition to check if we have it, and install it if necessary.
if (!("openNLPmodels.en" %in% installed.packages())){
install.packages("openNLPmodels.en",
repos = 'http://datacube.wu.ac.at/',
type = 'source',
quiet = TRUE)}
# Now, we load all the packages used.
library(ggplot2)
library(graphics)
library(ngram)
library(NLP)
library(openNLP)
library(openNLPmodels.en)
library(qdap)
library(quanteda)
library(RColorBrewer)
library(rJava)
library(rmarkdown)
library(sentimentr)
library(stringr)
library(tibble)
library(tidyr)
library(tidytext)
library(topicmodels)
library(tm)
library(wordcloud)
# Calculate the number of characters in each sentence.
# Add a new column to spooky containing this information.
spooky_with_lengths <-
spooky %>%
mutate(charLength=nchar(.$text))
# We set up different dataframes for each author to facilitate separate charts.
# This will facilitate getting further into individual details later.
# We'll remove both the sentence identifiers as well as the author names,
# because we're not using the former, and the latter is implied
# by the new dataframes' names.
# Note that running summary() on any of these dataframes takes so long that,
# in effect, it causes R to crash. So we'll make sure we don't do that!
EAP <-
spooky_with_lengths %>%
filter(author=="EAP") %>%
select(text:charLength)
HPL <-
spooky_with_lengths %>%
filter(author=="HPL") %>%
select(text:charLength)
MWS <-
spooky_with_lengths %>%
filter(author=="MWS") %>%
select(text:charLength)
EAP <- arrange(EAP, desc(charLength))
HPL <- arrange(HPL, desc(charLength))
MWS <- arrange(MWS, desc(charLength))
# (The following console displays are not PDF-friendly.)
# Poe's longest and shortest sentences:
head(EAP$text, n=1)
tail(EAP$text, n=1)
# Lovecraft's:
head(HPL$text, n=1)
tail(HPL$text, n=1)
# Shelley's:
head(MWS$text, n=1)
tail(MWS$text, n=1)
